Network Performance
===================

Papyrus network designed as high loaded solution that should be able to process more than 1000 tps.
To achieve these performance results we completely changed most of ethereum transaction constants.

Results of this tuning you may see below:


``peer.go`` class that contains constants that are responsible for queue sizes.

.. code-block:: javascript
      :emphasize-lines: 5,10,15 
      
            // maxQueuedTxs is the maximum number of transaction lists to queue up before
            // dropping broadcasts. This is a sensitive number as a transaction list might
            // contain a single transaction, or thousands.
            maxQueuedTxs = /*128*/ 16384

            // maxQueuedProps is the maximum number of block propagations to queue up before
            // dropping broadcasts. There's not much point in queueing stale blocks, so a few
            // that might cover uncles should be enough.
            maxQueuedProps = /*4*/ 32

            // maxQueuedAnns is the maximum number of block announcements to queue up before
            // dropping broadcasts. Similarly to block propagations, there's no point to queue
            // above some healthy uncle limit, so use that.
            maxQueuedAnns = /*4*/ 32
            
            handshakeTimeout = 5 * time.Second
      ) 


*   ``tx_pool.go`` class that contains most of logic for the transaction pool:

.. code-block:: javascript
      :linenos:
      :emphasize-lines: 3,10,11,12,13

        const (
            // chainHeadChanSize is the size of channel listening to ChainHeadEvent.
            chainHeadChanSize =  /*10*/ 100
        )
        ...
        DefaultTxPoolConfig = TxPoolConfig{
            PriceLimit: 1,
            PriceBump:  10,

            AccountSlots: /*16*/ 8192,
            GlobalSlots:  /*4096*/ 131072,
            AccountQueue: /*64*/ 4096,
            GlobalQueue:  /*1024*/ 32768,
        } 



After that we added transaction batching.
This kind of transaction packaging lets us to drastically increase network performance without compromising security. 
In order to unlock the full potential of this approach, we also had to rework the queue sizes for pending and queued transactions.
While these changes implied new changes in parameters of the maximum number of permissible transactions, and, most importantly, 
in the total number of transactions.

Finally, we overhauled buffers.

The result is a tenfold increase in performance. For multiple tests, we used a specific utility to load the network with 1500 transactions every second.
The test results showed that the network successfully handles 1500 transactions per second and works stably at such a load for a long period of time.
Below you can find the logs of the utility and the logs of the node.
The logs show that all 1500 transactions fall into a block, which is generated every second. During the test, we used the type of configuration, suggesting the entire load to be applied to one gateway node, while the gateway-node is not engaged in the generation of blocks.
Blocks are generated by several sealer nodes.

Results



Utility logs:

.. image:: images/utility_logs.png

Node logs:

.. image:: images/node_logs.png

A visual representation, which can be seen on our monitor explorer (screenshot):

.. image:: images/explorer_logs.png

The test shows, that 1500 transactions fall into a block every second it is generated.

As a result, we got the desired and unique combination of a quality network.
